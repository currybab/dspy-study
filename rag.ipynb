{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a8991f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "\n",
    "lm = dspy.LM(\"openai/gpt-4o-mini\")\n",
    "dspy.configure(lm=lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "173ab51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ujson\n",
    "from dspy.utils import download\n",
    "\n",
    "# Download question--answer pairs from the RAG-QA Arena \"Tech\" dataset.\n",
    "# download(\n",
    "#     \"https://huggingface.co/dspy/cache/resolve/main/ragqa_arena_tech_examples.jsonl\"\n",
    "# )\n",
    "\n",
    "with open(\"ragqa_arena_tech_examples.jsonl\") as f:\n",
    "    data = [ujson.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ea9d832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'why igp is used in mpls?',\n",
       " 'response': \"An IGP exchanges routing prefixes between gateways/routers.  \\nWithout a routing protocol, you'd have to configure each route on every router and you'd have no dynamic updates when routes change because of link failures. \\nFuthermore, within an MPLS network, an IGP is vital for advertising the internal topology and ensuring connectivity for MP-BGP inside the network.\",\n",
       " 'gold_doc_ids': [2822, 2823]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2664ac5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Example({'question': 'why are my text messages coming up as maybe?', 'response': 'This is part of the Proactivity features new with iOS 9: It looks at info in emails to see if anyone with this number sent you an email and if it finds the phone number associated with a contact from your email, it will show you \"Maybe\". \\n\\nHowever, it has been suggested there is a bug in iOS 11.2 that can result in \"Maybe\" being displayed even when \"Find Contacts in Other Apps\" is disabled.', 'gold_doc_ids': [3956, 3957, 8034]}) (input_keys={'question'})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dspy\n",
    "\n",
    "data = [dspy.Example(**d).with_inputs(\"question\") for d in data]\n",
    "\n",
    "# Let's pick an `example` here from the data.\n",
    "example = data[2]\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93fd7d0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['question', 'response', 'gold_doc_ids']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03851fe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 300, 500)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random.Random(0).shuffle(data)\n",
    "trainset, devset, testset = data[:200], data[200:500], data[500:1000]\n",
    "\n",
    "len(trainset), len(devset), len(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cbdfe82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    reasoning='The placement of curly braces on their own line is largely a matter of coding style and conventions. In many programming languages, such as Java, C#, and JavaScript, it is common to place opening curly braces on the same line as the statement that precedes them, while closing curly braces are often placed on a new line. This style is known as \"K&R style.\" However, some developers prefer to place both opening and closing curly braces on their own lines for better readability, especially in languages like Python or when following certain style guides like the Allman style. Ultimately, the decision should be based on team conventions, readability, and personal preference.',\n",
       "    response=\"Curly braces can either appear on their own line or on the same line as the preceding statement, depending on the coding style you choose to follow. It's important to be consistent with whichever style you adopt, and to consider team conventions and readability when making your choice.\"\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cot = dspy.ChainOfThought(\"question -> response\")\n",
    "cot(question=\"should curly braces appear on their own line?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b69d98f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: \t why are my text messages coming up as maybe?\n",
      "\n",
      "Gold Response: \t This is part of the Proactivity features new with iOS 9: It looks at info in emails to see if anyone with this number sent you an email and if it finds the phone number associated with a contact from your email, it will show you \"Maybe\". \n",
      "\n",
      "However, it has been suggested there is a bug in iOS 11.2 that can result in \"Maybe\" being displayed even when \"Find Contacts in Other Apps\" is disabled.\n",
      "\n",
      "Predicted Response: \t Your text messages are showing up as \"maybe\" likely because the recipient's phone does not recognize your number, possibly because you are not saved in their contacts. This feature is designed to help users identify potential spam or unknown senders. You might want to ask the recipient to save your number or check their messaging app settings for more information.\n",
      "\n",
      "Semantic F1 Score: 0.40\n"
     ]
    }
   ],
   "source": [
    "from dspy.evaluate import SemanticF1\n",
    "\n",
    "# Instantiate the metric.\n",
    "metric = SemanticF1(decompositional=True)\n",
    "\n",
    "# Produce a prediction from our `cot` module, using the `example` above as input.\n",
    "pred = cot(**example.inputs())\n",
    "\n",
    "# Compute the metric score for the prediction.\n",
    "score = metric(example, pred)\n",
    "\n",
    "print(f\"Question: \\t {example.question}\\n\")\n",
    "print(f\"Gold Response: \\t {example.response}\\n\")\n",
    "print(f\"Predicted Response: \\t {pred.response}\\n\")\n",
    "print(f\"Semantic F1 Score: {score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9751a6b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2025-07-13T15:29:16.535330]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `question` (str): \n",
      "2. `ground_truth` (str): \n",
      "3. `system_response` (str):\n",
      "Your output fields are:\n",
      "1. `reasoning` (str): \n",
      "2. `ground_truth_key_ideas` (str): enumeration of key ideas in the ground truth\n",
      "3. `system_response_key_ideas` (str): enumeration of key ideas in the system response\n",
      "4. `discussion` (str): discussion of the overlap between ground truth and system response\n",
      "5. `recall` (float): fraction (out of 1.0) of ground truth covered by the system response\n",
      "6. `precision` (float): fraction (out of 1.0) of system response covered by the ground truth\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## question ## ]]\n",
      "{question}\n",
      "\n",
      "[[ ## ground_truth ## ]]\n",
      "{ground_truth}\n",
      "\n",
      "[[ ## system_response ## ]]\n",
      "{system_response}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## ground_truth_key_ideas ## ]]\n",
      "{ground_truth_key_ideas}\n",
      "\n",
      "[[ ## system_response_key_ideas ## ]]\n",
      "{system_response_key_ideas}\n",
      "\n",
      "[[ ## discussion ## ]]\n",
      "{discussion}\n",
      "\n",
      "[[ ## recall ## ]]\n",
      "{recall}        # note: the value you produce must be a single float value\n",
      "\n",
      "[[ ## precision ## ]]\n",
      "{precision}        # note: the value you produce must be a single float value\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "In adhering to this structure, your objective is: \n",
      "        Compare a system's response to the ground truth to compute recall and precision of key ideas.\n",
      "        You will first enumerate key ideas in each response, discuss their overlap, and then report recall and precision.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## question ## ]]\n",
      "why are my text messages coming up as maybe?\n",
      "\n",
      "[[ ## ground_truth ## ]]\n",
      "This is part of the Proactivity features new with iOS 9: It looks at info in emails to see if anyone with this number sent you an email and if it finds the phone number associated with a contact from your email, it will show you \"Maybe\". \n",
      "\n",
      "However, it has been suggested there is a bug in iOS 11.2 that can result in \"Maybe\" being displayed even when \"Find Contacts in Other Apps\" is disabled.\n",
      "\n",
      "[[ ## system_response ## ]]\n",
      "Your text messages are showing up as \"maybe\" likely because the recipient's phone does not recognize your number, possibly because you are not saved in their contacts. This feature is designed to help users identify potential spam or unknown senders. You might want to ask the recipient to save your number or check their messaging app settings for more information.\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## ground_truth_key_ideas ## ]]`, then `[[ ## system_response_key_ideas ## ]]`, then `[[ ## discussion ## ]]`, then `[[ ## recall ## ]]` (must be formatted as a valid Python float), then `[[ ## precision ## ]]` (must be formatted as a valid Python float), and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## reasoning ## ]]\n",
      "The system response provides a plausible explanation for why text messages may show up as \"maybe,\" focusing on the recipient's contact list and the potential for spam identification. However, it does not mention the specific iOS feature that causes this behavior, nor does it address the potential bug in iOS 11.2 that could lead to this issue. The ground truth includes these details, which are essential for a complete understanding of the situation.\n",
      "\n",
      "[[ ## ground_truth_key_ideas ## ]]\n",
      "1. Proactivity features in iOS 9 look at email info to identify contacts.\n",
      "2. \"Maybe\" appears if the number is associated with an email contact.\n",
      "3. A bug in iOS 11.2 can cause \"Maybe\" to show even if \"Find Contacts in Other Apps\" is disabled.\n",
      "\n",
      "[[ ## system_response_key_ideas ## ]]\n",
      "1. Messages show as \"maybe\" if the recipient does not recognize the number.\n",
      "2. Suggests the recipient save the number or check messaging app settings.\n",
      "3. Designed to help identify potential spam or unknown senders.\n",
      "\n",
      "[[ ## discussion ## ]]\n",
      "There is some overlap between the ground truth and the system response. Both mention the idea that the recipient may not recognize the sender's number, which is a valid reason for the \"maybe\" label. However, the system response lacks the specific context of the iOS features and the bug mentioned in the ground truth. The ground truth provides a more comprehensive explanation, including the technical aspects of how the feature works and the potential bug, which the system response does not address.\n",
      "\n",
      "[[ ## recall ## ]]\n",
      "0.5\n",
      "\n",
      "[[ ## precision ## ]]\n",
      "0.3333333333333333\n",
      "\n",
      "[[ ## completed ## ]]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dspy.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36e3c67e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 126.02 / 300 (42.0%): 100%|██████████| 300/300 [01:30<00:00,  3.30it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/13 15:33:23 INFO dspy.evaluate.evaluate: Average Metric: 126.01753608119975 / 300 (42.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>example_response</th>\n",
       "      <th>gold_doc_ids</th>\n",
       "      <th>reasoning</th>\n",
       "      <th>pred_response</th>\n",
       "      <th>SemanticF1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>when to use c over c++, and c++ over c?</td>\n",
       "      <td>If you are equally familiar with both C++ and C, it's advisable to...</td>\n",
       "      <td>[733]</td>\n",
       "      <td>C and C++ are both powerful programming languages, but they serve ...</td>\n",
       "      <td>Use C when you need low-level programming, performance, and simpli...</td>\n",
       "      <td>✔️ [0.500]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>should images be stored in a git repository?</td>\n",
       "      <td>One viewpoint expresses that there is no significant downside, esp...</td>\n",
       "      <td>[6253, 6254, 6275, 6278, 8215]</td>\n",
       "      <td>Storing images in a Git repository can be problematic for several ...</td>\n",
       "      <td>It is generally not advisable to store images directly in a Git re...</td>\n",
       "      <td>✔️ [0.308]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       question  \\\n",
       "0       when to use c over c++, and c++ over c?   \n",
       "1  should images be stored in a git repository?   \n",
       "\n",
       "                                                        example_response  \\\n",
       "0  If you are equally familiar with both C++ and C, it's advisable to...   \n",
       "1  One viewpoint expresses that there is no significant downside, esp...   \n",
       "\n",
       "                     gold_doc_ids  \\\n",
       "0                           [733]   \n",
       "1  [6253, 6254, 6275, 6278, 8215]   \n",
       "\n",
       "                                                               reasoning  \\\n",
       "0  C and C++ are both powerful programming languages, but they serve ...   \n",
       "1  Storing images in a Git repository can be problematic for several ...   \n",
       "\n",
       "                                                           pred_response  \\\n",
       "0  Use C when you need low-level programming, performance, and simpli...   \n",
       "1  It is generally not advisable to store images directly in a Git re...   \n",
       "\n",
       "   SemanticF1  \n",
       "0  ✔️ [0.500]  \n",
       "1  ✔️ [0.308]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div style='\n",
       "                text-align: center;\n",
       "                font-size: 16px;\n",
       "                font-weight: bold;\n",
       "                color: #555;\n",
       "                margin: 10px 0;'>\n",
       "                ... 298 more rows not displayed ...\n",
       "            </div>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "EvaluationResult(score=42.01, results=<list of 300 results>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define an evaluator that we can re-use.\n",
    "evaluate = dspy.Evaluate(\n",
    "    devset=devset, metric=metric, num_threads=24, display_progress=True, display_table=2\n",
    ")\n",
    "\n",
    "# Evaluate the Chain-of-Thought program.\n",
    "evaluate(cot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e876823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 28436 documents. Will encode them below.\n",
      "Training a 32-byte FAISS index with 337 partitions, based on 28436 x 512-dim embeddings\n"
     ]
    }
   ],
   "source": [
    "max_characters = 6000  # for truncating >99th percentile of documents\n",
    "topk_docs_to_retrieve = 5  # number of documents to retrieve per search query\n",
    "\n",
    "with open(\"ragqa_arena_tech_corpus.jsonl\") as f:\n",
    "    corpus = [ujson.loads(line)[\"text\"][:max_characters] for line in f]\n",
    "    print(f\"Loaded {len(corpus)} documents. Will encode them below.\")\n",
    "\n",
    "embedder = dspy.Embedder(\"openai/text-embedding-3-small\", dimensions=512)\n",
    "search = dspy.retrievers.Embeddings(\n",
    "    embedder=embedder, corpus=corpus, k=topk_docs_to_retrieve\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1c3b6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAG(dspy.Module):\n",
    "    def __init__(self):\n",
    "        self.respond = dspy.ChainOfThought(\"context, question -> response\")\n",
    "\n",
    "    def forward(self, question):\n",
    "        context = search(question).passages\n",
    "        return self.respond(context=context, question=question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5479e0f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    reasoning=\"High memory and low memory in Linux refer to two distinct segments of the kernel's memory space. Low memory is the portion of memory that the kernel can access directly and is statically mapped at boot time, allowing for efficient access. High memory, on the other hand, is not permanently mapped in the kernel's address space and requires special handling (like mapping and unmapping) for the kernel to access it. This distinction is crucial for managing memory in a 32-bit architecture, where the kernel needs to access more memory than it can directly map. High memory is typically used for temporary data buffers, while low memory is used for kernel operations.\",\n",
       "    response=\"In Linux, high memory refers to the segment of memory that is not permanently mapped in the kernel's address space, requiring the kernel to map it temporarily for access. Low memory, conversely, is the portion that the kernel can access directly and is statically mapped at boot time. This separation allows user-space applications to operate in their own memory space without directly accessing kernel memory, enhancing system stability and security.\"\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag = RAG()\n",
    "rag(question=\"what are high memory and low memory on linux?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34a0f27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2025-07-13T15:39:07.901851]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `context` (str): \n",
      "2. `question` (str):\n",
      "Your output fields are:\n",
      "1. `reasoning` (str): \n",
      "2. `response` (str):\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## context ## ]]\n",
      "{context}\n",
      "\n",
      "[[ ## question ## ]]\n",
      "{question}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## response ## ]]\n",
      "{response}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "In adhering to this structure, your objective is: \n",
      "        Given the fields `context`, `question`, produce the fields `response`.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## context ## ]]\n",
      "[1] «As far as I remember, High Memory is used for application space and Low Memory for the kernel. Advantage is that (user-space) applications cant access kernel-space memory.»\n",
      "[2] «HIGHMEM is a range of kernels memory space, but it is NOT memory you access but its a place where you put what you want to access. A typical 32bit Linux virtual memory map is like: 0x00000000-0xbfffffff: user process (3GB) 0xc0000000-0xffffffff: kernel space (1GB) (CPU-specific vector and whatsoever are ignored here). Linux splits the 1GB kernel space into 2 pieces, LOWMEM and HIGHMEM. The split varies from installation to installation. If an installation chooses, say, 512MB-512MB for LOW and HIGH mems, the 512MB LOWMEM (0xc0000000-0xdfffffff) is statically mapped at the kernel boot time; usually the first so many bytes of the physical memory is used for this so that virtual and physical addresses in this range have a constant offset of, say, 0xc0000000. On the other hand, the latter 512MB (HIGHMEM) has no static mapping (although you could leave pages semi-permanently mapped there, but you must do so explicitly in your driver code). Instead, pages are temporarily mapped and unmapped here so that virtual and physical addresses in this range have no consistent mapping. Typical uses of HIGHMEM include single-time data buffers.»\n",
      "[3] «This is relevant to the Linux kernel; Im not sure how any Unix kernel handles this. The High Memory is the segment of memory that user-space programs can address. It cannot touch Low Memory. Low Memory is the segment of memory that the Linux kernel can address directly. If the kernel must access High Memory, it has to map it into its own address space first. There was a patch introduced recently that lets you control where the segment is. The tradeoff is that you can take addressable memory away from user space so that the kernel can have more memory that it does not have to map before using. Additional resources: http://tldp.org/HOWTO/KernelAnalysis-HOWTO-7.html http://linux-mm.org/HighMemory»\n",
      "[4] «The first reference to turn to is Linux Device Drivers (available both online and in book form), particularly chapter 15 which has a section on the topic. In an ideal world, every system component would be able to map all the memory it ever needs to access. And this is the case for processes on Linux and most operating systems: a 32-bit process can only access a little less than 2^32 bytes of virtual memory (in fact about 3GB on a typical Linux 32-bit architecture). It gets difficult for the kernel, which needs to be able to map the full memory of the process whose system call its executing, plus the whole physical memory, plus any other memory-mapped hardware device. So when a 32-bit kernel needs to map more than 4GB of memory, it must be compiled with high memory support. High memory is memory which is not permanently mapped in the kernels address space. (Low memory is the opposite: it is always mapped, so you can access it in the kernel simply by dereferencing a pointer.) When you access high memory from kernel code, you need to call kmap first, to obtain a pointer from a page data structure (struct page). Calling kmap works whether the page is in high or low memory. There is also kmap_atomic which has added constraints but is more efficient on multiprocessor machines because it uses finer-grained locking. The pointer obtained through kmap is a resource: it uses up address space. Once youve finished with it, you must call kunmap (or kunmap_atomic) to free that resource; then the pointer is no longer valid, and the contents of the page cant be accessed until you call kmap again.»\n",
      "[5] «Since you dont mention, Im assuming this is on Linux. Any of the following should show you (with root): dmidecode -t memory dmidecode -t 16 lshw -class memory»\n",
      "\n",
      "[[ ## question ## ]]\n",
      "what are high memory and low memory on linux?\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## response ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## reasoning ## ]]\n",
      "High memory and low memory in Linux refer to two distinct segments of the kernel's memory space. Low memory is the portion of memory that the kernel can access directly and is statically mapped at boot time, allowing for efficient access. High memory, on the other hand, is not permanently mapped in the kernel's address space and requires special handling (like mapping and unmapping) for the kernel to access it. This distinction is crucial for managing memory in a 32-bit architecture, where the kernel needs to access more memory than it can directly map. High memory is typically used for temporary data buffers, while low memory is used for kernel operations.\n",
      "\n",
      "[[ ## response ## ]]\n",
      "In Linux, high memory refers to the segment of memory that is not permanently mapped in the kernel's address space, requiring the kernel to map it temporarily for access. Low memory, conversely, is the portion that the kernel can access directly and is statically mapped at boot time. This separation allows user-space applications to operate in their own memory space without directly accessing kernel memory, enhancing system stability and security.\n",
      "\n",
      "[[ ## completed ## ]]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dspy.inspect_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d31fb982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 164.89 / 300 (55.0%): 100%|██████████| 300/300 [01:55<00:00,  2.60it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/13 15:41:16 INFO dspy.evaluate.evaluate: Average Metric: 164.88770316639904 / 300 (55.0%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>example_response</th>\n",
       "      <th>gold_doc_ids</th>\n",
       "      <th>reasoning</th>\n",
       "      <th>pred_response</th>\n",
       "      <th>SemanticF1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>when to use c over c++, and c++ over c?</td>\n",
       "      <td>If you are equally familiar with both C++ and C, it's advisable to...</td>\n",
       "      <td>[733]</td>\n",
       "      <td>C should be used over C++ primarily in scenarios where simplicity ...</td>\n",
       "      <td>Use C over C++ when working on embedded systems or projects that r...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>should images be stored in a git repository?</td>\n",
       "      <td>One viewpoint expresses that there is no significant downside, esp...</td>\n",
       "      <td>[6253, 6254, 6275, 6278, 8215]</td>\n",
       "      <td>Storing images in a Git repository can be problematic due to Git's...</td>\n",
       "      <td>While it is technically possible to store images in a Git reposito...</td>\n",
       "      <td>✔️ [0.500]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       question  \\\n",
       "0       when to use c over c++, and c++ over c?   \n",
       "1  should images be stored in a git repository?   \n",
       "\n",
       "                                                        example_response  \\\n",
       "0  If you are equally familiar with both C++ and C, it's advisable to...   \n",
       "1  One viewpoint expresses that there is no significant downside, esp...   \n",
       "\n",
       "                     gold_doc_ids  \\\n",
       "0                           [733]   \n",
       "1  [6253, 6254, 6275, 6278, 8215]   \n",
       "\n",
       "                                                               reasoning  \\\n",
       "0  C should be used over C++ primarily in scenarios where simplicity ...   \n",
       "1  Storing images in a Git repository can be problematic due to Git's...   \n",
       "\n",
       "                                                           pred_response  \\\n",
       "0  Use C over C++ when working on embedded systems or projects that r...   \n",
       "1  While it is technically possible to store images in a Git reposito...   \n",
       "\n",
       "   SemanticF1  \n",
       "0              \n",
       "1  ✔️ [0.500]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div style='\n",
       "                text-align: center;\n",
       "                font-size: 16px;\n",
       "                font-weight: bold;\n",
       "                color: #555;\n",
       "                margin: 10px 0;'>\n",
       "                ... 298 more rows not displayed ...\n",
       "            </div>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "EvaluationResult(score=54.96, results=<list of 300 results>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(RAG())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "228c3e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/13 15:41:43 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "RUNNING WITH THE FOLLOWING MEDIUM AUTO RUN SETTINGS:\n",
      "num_trials: 18\n",
      "minibatch: True\n",
      "num_fewshot_candidates: 12\n",
      "num_instruct_candidates: 6\n",
      "valset size: 160\n",
      "\n",
      "2025/07/13 15:41:43 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "==> STEP 1: BOOTSTRAP FEWSHOT EXAMPLES <==\n",
      "2025/07/13 15:41:43 INFO dspy.teleprompt.mipro_optimizer_v2: These will be used as few-shot example candidates for our program and for creating instructions.\n",
      "\n",
      "2025/07/13 15:41:43 INFO dspy.teleprompt.mipro_optimizer_v2: Bootstrapping N=12 sets of demonstrations...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapping set 1/12\n",
      "Bootstrapping set 2/12\n",
      "Bootstrapping set 3/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 5/40 [00:43<05:07,  8.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 5 examples for up to 1 rounds, amounting to 5 attempts.\n",
      "Bootstrapping set 4/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 6/40 [00:50<04:47,  8.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 6 examples for up to 1 rounds, amounting to 6 attempts.\n",
      "Bootstrapping set 5/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 2/40 [00:16<05:19,  8.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 2 examples for up to 1 rounds, amounting to 2 attempts.\n",
      "Bootstrapping set 6/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 3/40 [00:25<05:20,  8.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 3 examples for up to 1 rounds, amounting to 3 attempts.\n",
      "Bootstrapping set 7/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 2/40 [00:16<05:19,  8.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 2 examples for up to 1 rounds, amounting to 2 attempts.\n",
      "Bootstrapping set 8/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 5/40 [00:38<04:28,  7.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 5 examples for up to 1 rounds, amounting to 5 attempts.\n",
      "Bootstrapping set 9/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 2/40 [00:20<06:31, 10.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 2 full traces after 2 examples for up to 1 rounds, amounting to 2 attempts.\n",
      "Bootstrapping set 10/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 2/40 [00:15<05:03,  7.98s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 2 examples for up to 1 rounds, amounting to 2 attempts.\n",
      "Bootstrapping set 11/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▎         | 1/40 [00:09<06:03,  9.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 1 examples for up to 1 rounds, amounting to 1 attempts.\n",
      "Bootstrapping set 12/12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 3/40 [00:33<06:48, 11.04s/it]\n",
      "2025/07/13 15:46:15 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "==> STEP 2: PROPOSE INSTRUCTION CANDIDATES <==\n",
      "2025/07/13 15:46:15 INFO dspy.teleprompt.mipro_optimizer_v2: We will use the few-shot examples from the previous step, a generated dataset summary, a summary of the program code, and a randomly selected prompting tip to propose instructions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 1 full traces after 3 examples for up to 1 rounds, amounting to 3 attempts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/13 15:46:26 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "Proposing N=6 instructions...\n",
      "\n",
      "2025/07/13 15:46:26 WARNING dspy.primitives.module: Calling GenerateModuleInstruction.forward() directly is discouraged. Please use GenerateModuleInstruction() instead.\n",
      "2025/07/13 15:46:31 WARNING dspy.primitives.module: Calling GenerateModuleInstruction.forward() directly is discouraged. Please use GenerateModuleInstruction() instead.\n",
      "2025/07/13 15:46:37 WARNING dspy.primitives.module: Calling GenerateModuleInstruction.forward() directly is discouraged. Please use GenerateModuleInstruction() instead.\n",
      "2025/07/13 15:46:42 WARNING dspy.primitives.module: Calling GenerateModuleInstruction.forward() directly is discouraged. Please use GenerateModuleInstruction() instead.\n",
      "2025/07/13 15:46:46 WARNING dspy.primitives.module: Calling GenerateModuleInstruction.forward() directly is discouraged. Please use GenerateModuleInstruction() instead.\n",
      "2025/07/13 15:46:52 WARNING dspy.primitives.module: Calling GenerateModuleInstruction.forward() directly is discouraged. Please use GenerateModuleInstruction() instead.\n",
      "2025/07/13 15:46:56 INFO dspy.teleprompt.mipro_optimizer_v2: Proposed Instructions for Predictor 0:\n",
      "\n",
      "2025/07/13 15:46:56 INFO dspy.teleprompt.mipro_optimizer_v2: 0: Given the fields `context`, `question`, produce the fields `response`.\n",
      "\n",
      "2025/07/13 15:46:56 INFO dspy.teleprompt.mipro_optimizer_v2: 1: Imagine you are a technical support agent in a high-pressure environment where users urgently need assistance with their macOS and shell scripting issues. Your task is to provide clear, actionable solutions based on the context provided. Given the fields `context` and `question`, produce a comprehensive `response` that not only answers the question but also explains the reasoning behind your answer step by step, ensuring that the user can understand and apply the solution effectively.\n",
      "\n",
      "2025/07/13 15:46:56 INFO dspy.teleprompt.mipro_optimizer_v2: 2: You are a technical expert in macOS and shell scripting. Given the fields `context` that contains relevant information and a `question` that seeks specific details from that context, produce the fields `reasoning` and `response`. Ensure your response includes a clear thought process that logically addresses the question based on the provided context.\n",
      "\n",
      "2025/07/13 15:46:56 INFO dspy.teleprompt.mipro_optimizer_v2: 3: Generate a detailed response based on the provided `context` and `question`, ensuring that the response is informative, clear, and directly addresses the user's inquiry.\n",
      "\n",
      "2025/07/13 15:46:56 INFO dspy.teleprompt.mipro_optimizer_v2: 4: Given the fields `context` and `question`, generate a structured response that includes both a reasoned explanation and a clear answer. Ensure that the response is informative and easy to understand, following a logical flow that addresses the user's query effectively.\n",
      "\n",
      "2025/07/13 15:46:56 INFO dspy.teleprompt.mipro_optimizer_v2: 5: Using the provided `context` and `question`, generate a detailed `response` that includes a clear explanation and examples if applicable. Ensure that the reasoning process is articulated to enhance understanding.\n",
      "\n",
      "2025/07/13 15:46:56 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "\n",
      "/Users/junpark/codingcoding/dspy/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025/07/13 15:46:56 INFO dspy.teleprompt.mipro_optimizer_v2: ==> STEP 3: FINDING OPTIMAL PROMPT PARAMETERS <==\n",
      "2025/07/13 15:46:56 INFO dspy.teleprompt.mipro_optimizer_v2: We will evaluate the program over a series of trials with different combinations of instructions and few-shot examples to find the optimal combination using Bayesian Optimization.\n",
      "\n",
      "2025/07/13 15:46:56 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 1 / 23 - Full Evaluation of Default Program ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 90.85 / 160 (56.8%): 100%|██████████| 160/160 [01:21<00:00,  1.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/13 15:48:18 INFO dspy.evaluate.evaluate: Average Metric: 90.85100066174321 / 160 (56.8%)\n",
      "2025/07/13 15:48:18 INFO dspy.teleprompt.mipro_optimizer_v2: Default program score: 56.78\n",
      "\n",
      "/Users/junpark/codingcoding/dspy/.venv/lib/python3.12/site-packages/optuna/_experimental.py:32: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n",
      "2025/07/13 15:48:18 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 2 / 23 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 21.75 / 35 (62.1%): 100%|██████████| 35/35 [00:21<00:00,  1.61it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/13 15:48:40 INFO dspy.evaluate.evaluate: Average Metric: 21.746202270134518 / 35 (62.1%)\n",
      "2025/07/13 15:48:40 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 62.13 on minibatch of size 35 with parameters ['Predictor 0: Instruction 1', 'Predictor 0: Few-Shot Set 6'].\n",
      "2025/07/13 15:48:40 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [62.13]\n",
      "2025/07/13 15:48:40 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [56.78]\n",
      "2025/07/13 15:48:40 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 56.78\n",
      "2025/07/13 15:48:40 INFO dspy.teleprompt.mipro_optimizer_v2: =========================================\n",
      "\n",
      "\n",
      "2025/07/13 15:48:40 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 3 / 23 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 18.92 / 35 (54.0%): 100%|██████████| 35/35 [00:48<00:00,  1.38s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/13 15:49:29 INFO dspy.evaluate.evaluate: Average Metric: 18.91570953788717 / 35 (54.0%)\n",
      "2025/07/13 15:49:29 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 54.04 on minibatch of size 35 with parameters ['Predictor 0: Instruction 4', 'Predictor 0: Few-Shot Set 2'].\n",
      "2025/07/13 15:49:29 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [62.13, 54.04]\n",
      "2025/07/13 15:49:29 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [56.78]\n",
      "2025/07/13 15:49:29 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 56.78\n",
      "2025/07/13 15:49:29 INFO dspy.teleprompt.mipro_optimizer_v2: =========================================\n",
      "\n",
      "\n",
      "2025/07/13 15:49:29 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 4 / 23 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 22.11 / 35 (63.2%): 100%|██████████| 35/35 [00:19<00:00,  1.78it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/13 15:49:48 INFO dspy.evaluate.evaluate: Average Metric: 22.1125846187646 / 35 (63.2%)\n",
      "2025/07/13 15:49:48 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 63.18 on minibatch of size 35 with parameters ['Predictor 0: Instruction 0', 'Predictor 0: Few-Shot Set 6'].\n",
      "2025/07/13 15:49:48 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [62.13, 54.04, 63.18]\n",
      "2025/07/13 15:49:48 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [56.78]\n",
      "2025/07/13 15:49:48 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 56.78\n",
      "2025/07/13 15:49:48 INFO dspy.teleprompt.mipro_optimizer_v2: =========================================\n",
      "\n",
      "\n",
      "2025/07/13 15:49:48 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 5 / 23 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 21.81 / 35 (62.3%): 100%|██████████| 35/35 [00:21<00:00,  1.60it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/13 15:50:10 INFO dspy.evaluate.evaluate: Average Metric: 21.81279328156445 / 35 (62.3%)\n",
      "2025/07/13 15:50:10 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 62.32 on minibatch of size 35 with parameters ['Predictor 0: Instruction 2', 'Predictor 0: Few-Shot Set 4'].\n",
      "2025/07/13 15:50:10 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [62.13, 54.04, 63.18, 62.32]\n",
      "2025/07/13 15:50:10 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [56.78]\n",
      "2025/07/13 15:50:10 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 56.78\n",
      "2025/07/13 15:50:10 INFO dspy.teleprompt.mipro_optimizer_v2: =========================================\n",
      "\n",
      "\n",
      "2025/07/13 15:50:10 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 6 / 23 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 20.26 / 35 (57.9%): 100%|██████████| 35/35 [00:28<00:00,  1.24it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/13 15:50:38 INFO dspy.evaluate.evaluate: Average Metric: 20.263546886058187 / 35 (57.9%)\n",
      "2025/07/13 15:50:38 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 57.9 on minibatch of size 35 with parameters ['Predictor 0: Instruction 3', 'Predictor 0: Few-Shot Set 5'].\n",
      "2025/07/13 15:50:38 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [62.13, 54.04, 63.18, 62.32, 57.9]\n",
      "2025/07/13 15:50:38 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [56.78]\n",
      "2025/07/13 15:50:38 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 56.78\n",
      "2025/07/13 15:50:38 INFO dspy.teleprompt.mipro_optimizer_v2: =========================================\n",
      "\n",
      "\n",
      "2025/07/13 15:50:38 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 7 / 23 - Full Evaluation =====\n",
      "2025/07/13 15:50:38 INFO dspy.teleprompt.mipro_optimizer_v2: Doing full eval on next top averaging program (Avg Score: 63.18) from minibatch trials...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 95.74 / 160 (59.8%): 100%|██████████| 160/160 [01:23<00:00,  1.91it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/13 15:52:02 INFO dspy.evaluate.evaluate: Average Metric: 95.73659981271513 / 160 (59.8%)\n",
      "2025/07/13 15:52:02 INFO dspy.teleprompt.mipro_optimizer_v2: \u001b[92mNew best full eval score!\u001b[0m Score: 59.84\n",
      "2025/07/13 15:52:02 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [56.78, 59.84]\n",
      "2025/07/13 15:52:02 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 59.84\n",
      "2025/07/13 15:52:02 INFO dspy.teleprompt.mipro_optimizer_v2: =======================\n",
      "2025/07/13 15:52:02 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "\n",
      "2025/07/13 15:52:02 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 8 / 23 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 22.25 / 35 (63.6%): 100%|██████████| 35/35 [00:20<00:00,  1.70it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/13 15:52:23 INFO dspy.evaluate.evaluate: Average Metric: 22.249721355623993 / 35 (63.6%)\n",
      "2025/07/13 15:52:23 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 63.57 on minibatch of size 35 with parameters ['Predictor 0: Instruction 4', 'Predictor 0: Few-Shot Set 6'].\n",
      "2025/07/13 15:52:23 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [62.13, 54.04, 63.18, 62.32, 57.9, 63.57]\n",
      "2025/07/13 15:52:23 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [56.78, 59.84]\n",
      "2025/07/13 15:52:23 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 59.84\n",
      "2025/07/13 15:52:23 INFO dspy.teleprompt.mipro_optimizer_v2: =========================================\n",
      "\n",
      "\n",
      "2025/07/13 15:52:23 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 9 / 23 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 21.41 / 35 (61.2%): 100%|██████████| 35/35 [00:22<00:00,  1.54it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/13 15:52:46 INFO dspy.evaluate.evaluate: Average Metric: 21.41353242436359 / 35 (61.2%)\n",
      "2025/07/13 15:52:46 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 61.18 on minibatch of size 35 with parameters ['Predictor 0: Instruction 5', 'Predictor 0: Few-Shot Set 1'].\n",
      "2025/07/13 15:52:46 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [62.13, 54.04, 63.18, 62.32, 57.9, 63.57, 61.18]\n",
      "2025/07/13 15:52:46 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [56.78, 59.84]\n",
      "2025/07/13 15:52:46 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 59.84\n",
      "2025/07/13 15:52:46 INFO dspy.teleprompt.mipro_optimizer_v2: =========================================\n",
      "\n",
      "\n",
      "2025/07/13 15:52:46 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 10 / 23 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 19.86 / 35 (56.7%): 100%|██████████| 35/35 [00:21<00:00,  1.63it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/13 15:53:07 INFO dspy.evaluate.evaluate: Average Metric: 19.85791772226103 / 35 (56.7%)\n",
      "2025/07/13 15:53:07 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 56.74 on minibatch of size 35 with parameters ['Predictor 0: Instruction 3', 'Predictor 0: Few-Shot Set 3'].\n",
      "2025/07/13 15:53:07 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [62.13, 54.04, 63.18, 62.32, 57.9, 63.57, 61.18, 56.74]\n",
      "2025/07/13 15:53:07 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [56.78, 59.84]\n",
      "2025/07/13 15:53:07 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 59.84\n",
      "2025/07/13 15:53:07 INFO dspy.teleprompt.mipro_optimizer_v2: ==========================================\n",
      "\n",
      "\n",
      "2025/07/13 15:53:07 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 11 / 23 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 20.94 / 35 (59.8%): 100%|██████████| 35/35 [00:23<00:00,  1.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/13 15:53:31 INFO dspy.evaluate.evaluate: Average Metric: 20.937048132799298 / 35 (59.8%)\n",
      "2025/07/13 15:53:31 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 59.82 on minibatch of size 35 with parameters ['Predictor 0: Instruction 4', 'Predictor 0: Few-Shot Set 11'].\n",
      "2025/07/13 15:53:31 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [62.13, 54.04, 63.18, 62.32, 57.9, 63.57, 61.18, 56.74, 59.82]\n",
      "2025/07/13 15:53:31 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [56.78, 59.84]\n",
      "2025/07/13 15:53:31 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 59.84\n",
      "2025/07/13 15:53:31 INFO dspy.teleprompt.mipro_optimizer_v2: ==========================================\n",
      "\n",
      "\n",
      "2025/07/13 15:53:31 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 12 / 23 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 21.08 / 35 (60.2%): 100%|██████████| 35/35 [00:01<00:00, 19.62it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/13 15:53:33 INFO dspy.evaluate.evaluate: Average Metric: 21.075892800359945 / 35 (60.2%)\n",
      "2025/07/13 15:53:33 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 60.22 on minibatch of size 35 with parameters ['Predictor 0: Instruction 0', 'Predictor 0: Few-Shot Set 6'].\n",
      "2025/07/13 15:53:33 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [62.13, 54.04, 63.18, 62.32, 57.9, 63.57, 61.18, 56.74, 59.82, 60.22]\n",
      "2025/07/13 15:53:33 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [56.78, 59.84]\n",
      "2025/07/13 15:53:33 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 59.84\n",
      "2025/07/13 15:53:33 INFO dspy.teleprompt.mipro_optimizer_v2: ==========================================\n",
      "\n",
      "\n",
      "2025/07/13 15:53:33 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 13 / 23 - Full Evaluation =====\n",
      "2025/07/13 15:53:33 INFO dspy.teleprompt.mipro_optimizer_v2: Doing full eval on next top averaging program (Avg Score: 63.57) from minibatch trials...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 95.28 / 160 (59.6%): 100%|██████████| 160/160 [00:50<00:00,  3.17it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/13 15:54:23 INFO dspy.evaluate.evaluate: Average Metric: 95.28297398123125 / 160 (59.6%)\n",
      "2025/07/13 15:54:23 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [56.78, 59.84, 59.55]\n",
      "2025/07/13 15:54:23 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 59.84\n",
      "2025/07/13 15:54:23 INFO dspy.teleprompt.mipro_optimizer_v2: =======================\n",
      "2025/07/13 15:54:23 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "\n",
      "2025/07/13 15:54:23 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 14 / 23 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 20.55 / 35 (58.7%): 100%|██████████| 35/35 [00:07<00:00,  4.58it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/13 15:54:31 INFO dspy.evaluate.evaluate: Average Metric: 20.55293935939425 / 35 (58.7%)\n",
      "2025/07/13 15:54:31 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 58.72 on minibatch of size 35 with parameters ['Predictor 0: Instruction 4', 'Predictor 0: Few-Shot Set 6'].\n",
      "2025/07/13 15:54:31 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [62.13, 54.04, 63.18, 62.32, 57.9, 63.57, 61.18, 56.74, 59.82, 60.22, 58.72]\n",
      "2025/07/13 15:54:31 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [56.78, 59.84, 59.55]\n",
      "2025/07/13 15:54:31 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 59.84\n",
      "2025/07/13 15:54:31 INFO dspy.teleprompt.mipro_optimizer_v2: ==========================================\n",
      "\n",
      "\n",
      "2025/07/13 15:54:31 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 15 / 23 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 22.67 / 35 (64.8%): 100%|██████████| 35/35 [00:22<00:00,  1.57it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/13 15:54:53 INFO dspy.evaluate.evaluate: Average Metric: 22.66652710762648 / 35 (64.8%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/13 15:54:54 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 64.76 on minibatch of size 35 with parameters ['Predictor 0: Instruction 2', 'Predictor 0: Few-Shot Set 6'].\n",
      "2025/07/13 15:54:54 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [62.13, 54.04, 63.18, 62.32, 57.9, 63.57, 61.18, 56.74, 59.82, 60.22, 58.72, 64.76]\n",
      "2025/07/13 15:54:54 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [56.78, 59.84, 59.55]\n",
      "2025/07/13 15:54:54 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 59.84\n",
      "2025/07/13 15:54:54 INFO dspy.teleprompt.mipro_optimizer_v2: ==========================================\n",
      "\n",
      "\n",
      "2025/07/13 15:54:54 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 16 / 23 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 21.30 / 35 (60.9%): 100%|██████████| 35/35 [00:18<00:00,  1.86it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/13 15:55:12 INFO dspy.evaluate.evaluate: Average Metric: 21.303550638625808 / 35 (60.9%)\n",
      "2025/07/13 15:55:12 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 60.87 on minibatch of size 35 with parameters ['Predictor 0: Instruction 2', 'Predictor 0: Few-Shot Set 6'].\n",
      "2025/07/13 15:55:12 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [62.13, 54.04, 63.18, 62.32, 57.9, 63.57, 61.18, 56.74, 59.82, 60.22, 58.72, 64.76, 60.87]\n",
      "2025/07/13 15:55:12 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [56.78, 59.84, 59.55]\n",
      "2025/07/13 15:55:12 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 59.84\n",
      "2025/07/13 15:55:12 INFO dspy.teleprompt.mipro_optimizer_v2: ==========================================\n",
      "\n",
      "\n",
      "2025/07/13 15:55:12 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 17 / 23 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 19.18 / 35 (54.8%): 100%|██████████| 35/35 [00:22<00:00,  1.55it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/13 15:55:35 INFO dspy.evaluate.evaluate: Average Metric: 19.181659308797148 / 35 (54.8%)\n",
      "2025/07/13 15:55:35 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 54.8 on minibatch of size 35 with parameters ['Predictor 0: Instruction 2', 'Predictor 0: Few-Shot Set 8'].\n",
      "2025/07/13 15:55:35 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [62.13, 54.04, 63.18, 62.32, 57.9, 63.57, 61.18, 56.74, 59.82, 60.22, 58.72, 64.76, 60.87, 54.8]\n",
      "2025/07/13 15:55:35 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [56.78, 59.84, 59.55]\n",
      "2025/07/13 15:55:35 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 59.84\n",
      "2025/07/13 15:55:35 INFO dspy.teleprompt.mipro_optimizer_v2: ==========================================\n",
      "\n",
      "\n",
      "2025/07/13 15:55:35 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 18 / 23 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 22.53 / 35 (64.4%): 100%|██████████| 35/35 [00:59<00:00,  1.71s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/13 15:56:35 INFO dspy.evaluate.evaluate: Average Metric: 22.528202400450105 / 35 (64.4%)\n",
      "2025/07/13 15:56:35 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 64.37 on minibatch of size 35 with parameters ['Predictor 0: Instruction 5', 'Predictor 0: Few-Shot Set 10'].\n",
      "2025/07/13 15:56:35 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [62.13, 54.04, 63.18, 62.32, 57.9, 63.57, 61.18, 56.74, 59.82, 60.22, 58.72, 64.76, 60.87, 54.8, 64.37]\n",
      "2025/07/13 15:56:35 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [56.78, 59.84, 59.55]\n",
      "2025/07/13 15:56:35 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 59.84\n",
      "2025/07/13 15:56:35 INFO dspy.teleprompt.mipro_optimizer_v2: ==========================================\n",
      "\n",
      "\n",
      "2025/07/13 15:56:35 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 19 / 23 - Full Evaluation =====\n",
      "2025/07/13 15:56:35 INFO dspy.teleprompt.mipro_optimizer_v2: Doing full eval on next top averaging program (Avg Score: 64.37) from minibatch trials...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 96.74 / 160 (60.5%): 100%|██████████| 160/160 [00:56<00:00,  2.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/13 15:57:31 INFO dspy.evaluate.evaluate: Average Metric: 96.74258105497474 / 160 (60.5%)\n",
      "2025/07/13 15:57:31 INFO dspy.teleprompt.mipro_optimizer_v2: \u001b[92mNew best full eval score!\u001b[0m Score: 60.46\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/13 15:57:32 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [56.78, 59.84, 59.55, 60.46]\n",
      "2025/07/13 15:57:32 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 60.46\n",
      "2025/07/13 15:57:32 INFO dspy.teleprompt.mipro_optimizer_v2: =======================\n",
      "2025/07/13 15:57:32 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "\n",
      "2025/07/13 15:57:32 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 20 / 23 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 19.81 / 35 (56.6%): 100%|██████████| 35/35 [00:18<00:00,  1.89it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/13 15:57:50 INFO dspy.evaluate.evaluate: Average Metric: 19.805352243503528 / 35 (56.6%)\n",
      "2025/07/13 15:57:50 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 56.59 on minibatch of size 35 with parameters ['Predictor 0: Instruction 5', 'Predictor 0: Few-Shot Set 9'].\n",
      "2025/07/13 15:57:50 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [62.13, 54.04, 63.18, 62.32, 57.9, 63.57, 61.18, 56.74, 59.82, 60.22, 58.72, 64.76, 60.87, 54.8, 64.37, 56.59]\n",
      "2025/07/13 15:57:50 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [56.78, 59.84, 59.55, 60.46]\n",
      "2025/07/13 15:57:50 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 60.46\n",
      "2025/07/13 15:57:50 INFO dspy.teleprompt.mipro_optimizer_v2: ==========================================\n",
      "\n",
      "\n",
      "2025/07/13 15:57:50 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 21 / 23 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 20.02 / 35 (57.2%): 100%|██████████| 35/35 [00:01<00:00, 18.35it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/13 15:57:52 INFO dspy.evaluate.evaluate: Average Metric: 20.018292496614276 / 35 (57.2%)\n",
      "2025/07/13 15:57:52 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 57.2 on minibatch of size 35 with parameters ['Predictor 0: Instruction 5', 'Predictor 0: Few-Shot Set 10'].\n",
      "2025/07/13 15:57:52 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [62.13, 54.04, 63.18, 62.32, 57.9, 63.57, 61.18, 56.74, 59.82, 60.22, 58.72, 64.76, 60.87, 54.8, 64.37, 56.59, 57.2]\n",
      "2025/07/13 15:57:52 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [56.78, 59.84, 59.55, 60.46]\n",
      "2025/07/13 15:57:52 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 60.46\n",
      "2025/07/13 15:57:52 INFO dspy.teleprompt.mipro_optimizer_v2: ==========================================\n",
      "\n",
      "\n",
      "2025/07/13 15:57:52 INFO dspy.teleprompt.mipro_optimizer_v2: == Trial 22 / 23 - Minibatch ==\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 20.99 / 35 (60.0%): 100%|██████████| 35/35 [00:18<00:00,  1.90it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/13 15:58:11 INFO dspy.evaluate.evaluate: Average Metric: 20.990445514288535 / 35 (60.0%)\n",
      "2025/07/13 15:58:11 INFO dspy.teleprompt.mipro_optimizer_v2: Score: 59.97 on minibatch of size 35 with parameters ['Predictor 0: Instruction 3', 'Predictor 0: Few-Shot Set 10'].\n",
      "2025/07/13 15:58:11 INFO dspy.teleprompt.mipro_optimizer_v2: Minibatch scores so far: [62.13, 54.04, 63.18, 62.32, 57.9, 63.57, 61.18, 56.74, 59.82, 60.22, 58.72, 64.76, 60.87, 54.8, 64.37, 56.59, 57.2, 59.97]\n",
      "2025/07/13 15:58:11 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [56.78, 59.84, 59.55, 60.46]\n",
      "2025/07/13 15:58:11 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 60.46\n",
      "2025/07/13 15:58:11 INFO dspy.teleprompt.mipro_optimizer_v2: ==========================================\n",
      "\n",
      "\n",
      "2025/07/13 15:58:11 INFO dspy.teleprompt.mipro_optimizer_v2: ===== Trial 23 / 23 - Full Evaluation =====\n",
      "2025/07/13 15:58:11 INFO dspy.teleprompt.mipro_optimizer_v2: Doing full eval on next top averaging program (Avg Score: 62.815) from minibatch trials...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Metric: 93.73 / 160 (58.6%): 100%|██████████| 160/160 [00:56<00:00,  2.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/13 15:59:07 INFO dspy.evaluate.evaluate: Average Metric: 93.72821567828288 / 160 (58.6%)\n",
      "2025/07/13 15:59:07 INFO dspy.teleprompt.mipro_optimizer_v2: Full eval scores so far: [56.78, 59.84, 59.55, 60.46, 58.58]\n",
      "2025/07/13 15:59:07 INFO dspy.teleprompt.mipro_optimizer_v2: Best full score so far: 60.46\n",
      "2025/07/13 15:59:07 INFO dspy.teleprompt.mipro_optimizer_v2: =======================\n",
      "2025/07/13 15:59:07 INFO dspy.teleprompt.mipro_optimizer_v2: \n",
      "\n",
      "2025/07/13 15:59:07 INFO dspy.teleprompt.mipro_optimizer_v2: Returning best identified program with score 60.46!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tp = dspy.MIPROv2(\n",
    "    metric=metric, auto=\"medium\", num_threads=24\n",
    ")  # use fewer threads if your rate limit is small\n",
    "\n",
    "optimized_rag = tp.compile(\n",
    "    RAG(),\n",
    "    trainset=trainset,\n",
    "    max_bootstrapped_demos=2,\n",
    "    max_labeled_demos=2,\n",
    "    requires_permission_to_run=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3a568b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are correct; cmd+tab does not work on hidden or minimized windows. The Command + Tab shortcut only allows you to switch to applications that are currently open and in focus. If an application is minimized, you need to first restore it or use specific commands to manage minimized windows.\n"
     ]
    }
   ],
   "source": [
    "baseline = rag(question=\"cmd+tab does not work on hidden or minimized windows\")\n",
    "print(baseline.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf4284d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Command + Tab shortcut on macOS is intended for switching between applications that are currently open and visible. It does not work with minimized or hidden windows because these applications are not actively running in the foreground. When an application is minimized, it is not considered \"open\" in the same sense as those displayed on the screen. To access a minimized application, you can either click its icon in the Dock or use a different method, such as the Mission Control feature, to view all open windows, including minimized ones.\n"
     ]
    }
   ],
   "source": [
    "pred = optimized_rag(question=\"cmd+tab does not work on hidden or minimized windows\")\n",
    "print(pred.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2788a8d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2025-07-13T16:00:06.235507]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `context` (str): \n",
      "2. `question` (str):\n",
      "Your output fields are:\n",
      "1. `reasoning` (str): \n",
      "2. `response` (str):\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## context ## ]]\n",
      "{context}\n",
      "\n",
      "[[ ## question ## ]]\n",
      "{question}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## response ## ]]\n",
      "{response}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "In adhering to this structure, your objective is: \n",
      "        Given the fields `context`, `question`, produce the fields `response`.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## context ## ]]\n",
      "[1] «If you hold command and quickly tap tab you will cycle between your two most recently used applications without bringing up the heads up display. If you want to use a third party app Witch has options to ignore minimized windows.»\n",
      "[2] «Try this: On your Mac, Navigate to System Preferences Go to Mission Control Uncheck When switching to an application, switch to a Space with open windows for the application Try using the cmd+tab now.»\n",
      "[3] «Command + Tab until you get the apps icon. Before releasing the Command key, press and hold the Option key. You must switch to another app and let it take focus first. In other words, you cant just Command + Tab to another app and before actually selecting that app (by releasing the Command and Tab keys), switch right back to your minimized app, which you might attempt to do if you minimized it by accident or just simply changed your mind shortly after minimizing. Both the Command and left Option keys must be pressed on the same side (left or right) of the keyboard.»\n",
      "[4] «Command-option-click does not hide all open windows. As stated in the linked Apple article, this command hides all other open items leaving the clicked item visible. It is possible to hide all other items and minimize your most recently item with command+option+h+m. This is a combination of command+option+h - Hide Others and command+option+m - Minimize.»\n",
      "[5] «Cmd+` of course will work but I do it in different way. I do the Cmd+tab when i do that, I dont release the Cmd so the opened apps are still visible. While it is visible, I will press ▼. This way it will show all your opened application with animated displayed so you can navigate using arrow keys.»\n",
      "\n",
      "[[ ## question ## ]]\n",
      "cmd+tab does not work on hidden or minimized windows\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## response ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## reasoning ## ]]\n",
      "The context provided explains how to use the Command + Tab shortcut on a Mac to switch between applications, including details about handling minimized windows and using additional keys like Option. It also mentions that Command + Tab does not activate hidden or minimized windows directly. Instead, it requires the application to be in focus, and there are specific commands to manage minimized windows. Therefore, the statement that \"cmd+tab does not work on hidden or minimized windows\" is accurate, as the functionality of Command + Tab is limited to applications that are currently open and not minimized.\n",
      "\n",
      "[[ ## response ## ]]\n",
      "You are correct; cmd+tab does not work on hidden or minimized windows. The Command + Tab shortcut only allows you to switch to applications that are currently open and in focus. If an application is minimized, you need to first restore it or use specific commands to manage minimized windows.\n",
      "\n",
      "[[ ## completed ## ]]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2025-07-13T16:00:09.387083]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `context` (str): \n",
      "2. `question` (str):\n",
      "Your output fields are:\n",
      "1. `reasoning` (str): \n",
      "2. `response` (str):\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## context ## ]]\n",
      "{context}\n",
      "\n",
      "[[ ## question ## ]]\n",
      "{question}\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "{reasoning}\n",
      "\n",
      "[[ ## response ## ]]\n",
      "{response}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "In adhering to this structure, your objective is: \n",
      "        Using the provided `context` and `question`, generate a detailed `response` that includes a clear explanation and examples if applicable. Ensure that the reasoning process is articulated to enhance understanding.\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "This is an example of the task, though some input or output fields are not supplied.\n",
      "\n",
      "[[ ## question ## ]]\n",
      "what to do if caught in a physical pentest?\n",
      "\n",
      "\n",
      "\u001b[31mAssistant message:\u001b[0m\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "Not supplied for this particular example. \n",
      "\n",
      "[[ ## response ## ]]\n",
      "When engaging in a Red Team Engagement, if you are caught by security, ensure you follow the police's orders. \n",
      "They will verify your Permission to Attack and contact the individual responsible for authorizing your activity.  \n",
      "Claiming to be a \"security researcher\" or attempting to flee the scene are inadvisable strategies, as these could lead to further complications and misunderstandings with security personnel.\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## context ## ]]\n",
      "[1] «Slight revision It seems that the below has changed slightly, and Apple now checks which numbers/emails have been activated per device for sending messages. Therefore, my mobile number on my iPhone can be registered on my iCloud account, and allow me to receive message sent to my mobile number to be received on my iPad. Therefore you can have the conversation appear on multiple devices at once, and switch between them. iMessage will keep these conversations in sync. I disable this by specifying which accounts to be linked to which device when configuring iMessage. To expand on alexmullers answer it uses the Device ID to determine if another device is running iOS 5. This is done during registration, or when iMessage is configured under phone settings. Effectively the Device ID and Apple IDs/Mobile numbers are stored on the Apple Servers. It checks the Apple servers to determine if a number or email address is registered as an Apple ID and using iOS 5. It will then send the message via the Apple Servers first. It also uses text fallback, so if the other user is not using an iOS device, or iMessage is unavailable or down, or your data connection is down, it will send the message as a text. Text fallback can however be disabled. This does not affect normal texting. On the phone itself iMessages are identified via a blue background, and can show Delivered/Read for each message. SMS to the same person is still shown in a green background. It also uses the Device ID to determine which device to reply to. I have my email address and phone number configured on my iPhone and on my iPad only my email address. In Example I send a message to my wifes iPad using her email address from my iPhone, she receives it on the iPad, and the reply is sent back to my iPhone. I send a message via my iPad to her email address, the reply is sent back to my iPad, and not my iPhone. She sends a message to my iPhone using my mobile number from the iPad, it comes to my iPhone and bypasses the iPad completely and the reply goes back to her iPad. Its intelligent enough to know where the message came from and where to reply to.»\n",
      "[2] «iMessage (Free) iMessage, Apples own messaging platform, can send and receive messages on iOS (5 or later on iPhone, iPad, and iPod touch), macOS and watchOS, as long as they are connected to either a Wi-Fi or cellular network (3G). Starting with iOS 10, Messages includes support for third party apps.»\n",
      "[3] «iMessage is actually an instant messaging service, like Google Talk or AOL Instant Messenger, except iMessage is made by Apple and is only for Apple products. Only an iPhone with cellular can send SMS messages as well, and can automatically associate phone numbers of registered iMessage users with iMessage accounts, so if you try to use the app to send a text to a phone number registered to an iPhone, it will send an iMessage instead. iPads cannot send SMS messages to non-Apple devices nor an iMessage to a phone number not registered with iMessage from a Wi-Fi-only device. http://support.apple.com/kb/HT3529»\n",
      "[4] «Your iPhone uses the Messages app to send messages to other devices. However, it works a bit differently depending on what device the person you are messaging is using. When you send a Message, the iPhone looks on Apple servers to see if the recipient owns an Apple Device. Remember when you had to register your device with an Apple ID? This was putting your email in the Apple server. It also put your telephone number in the Apple server. If the server finds your recipient in the Apple servers, it automatcially sends a message via the Apple network, therefore not using the SMS network, which might incur charges (depending on your SMS or text message limits). If the Apple server does not find your recipient, then it sends the message via SMS or text messaging, over the carriers system. So, if you send a message to a friend who has an Android phone, the Apple server wont find that device in its database, and will then send the message via regular text messaging service, so the Android phone can receive it. This systems allows you to message anyone, and Apple simply figures out the best way to send the message, whether its via Apples system, which does not incur SMS fees, or via the carriers system, which might incur fees. (most users in the USA have unlimited text messaging plans these days, so this is less than a concern. If you have a limit of 100 messages, you can appreciate how this is a good thing.) OK, now to your question: your email: Messages is NOT sending a message via email. It is simply using the email (which is likely your Apple ID), as an identifier of your device. This lets other Apple users send you a message to either your phone number or email address. This is useful on iPads, iPod Touch, and Macs, who can not send to phone numbers, because they do not have phone service. So, with Messages on your iPhone, someone on their Mac can send you a message, and you can message back!»\n",
      "[5] «iMessages dont go through your cell phone provider so they dont necessarily know about them. iMessages go through your network connection so to your provider they look just like any other network/internet/browser traffic. If your text messages were from Apple device to Apple device (using iMessage for both sides), its not going to show up on the provider logs. If your text messages were from your iPhone (or other Apple device) to a non-apple device or an Apple device without a network connection but still connected to the cell network, that does go through your cell provider. They will have a log of those messages. You can tell which ones those are because the chat bubble on the Apple device is green instead of blue.»\n",
      "\n",
      "[[ ## question ## ]]\n",
      "how does imessage know that the recipient is an ios 5 device?\n",
      "\n",
      "\n",
      "\u001b[31mAssistant message:\u001b[0m\n",
      "\n",
      "[[ ## reasoning ## ]]\n",
      "iMessage determines if the recipient is using an iOS 5 device or later by checking the Apple servers during the registration or configuration of iMessage. When a user sets up iMessage, their device ID, Apple ID, and associated phone numbers or email addresses are stored on Apple servers. When a message is sent, the iPhone queries these servers to see if the recipient's phone number or email address is registered as an Apple ID and if it is linked to a device running iOS 5 or later. If the server confirms that the recipient is using a compatible device, the message is sent via the iMessage network. If not, the message is sent as a standard SMS.\n",
      "\n",
      "[[ ## response ## ]]\n",
      "iMessage knows that the recipient is using an iOS 5 device by checking the Apple servers during the message sending process. When you configure iMessage, your device ID and associated Apple ID or phone number are registered on these servers. When you send a message, your iPhone queries the servers to see if the recipient's number or email is linked to an Apple ID and if it corresponds to a device running iOS 5 or later. If the recipient is confirmed to be using a compatible device, the message is sent via iMessage; otherwise, it defaults to SMS.\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## context ## ]]\n",
      "[1] «If you hold command and quickly tap tab you will cycle between your two most recently used applications without bringing up the heads up display. If you want to use a third party app Witch has options to ignore minimized windows.»\n",
      "[2] «Try this: On your Mac, Navigate to System Preferences Go to Mission Control Uncheck When switching to an application, switch to a Space with open windows for the application Try using the cmd+tab now.»\n",
      "[3] «Command + Tab until you get the apps icon. Before releasing the Command key, press and hold the Option key. You must switch to another app and let it take focus first. In other words, you cant just Command + Tab to another app and before actually selecting that app (by releasing the Command and Tab keys), switch right back to your minimized app, which you might attempt to do if you minimized it by accident or just simply changed your mind shortly after minimizing. Both the Command and left Option keys must be pressed on the same side (left or right) of the keyboard.»\n",
      "[4] «Command-option-click does not hide all open windows. As stated in the linked Apple article, this command hides all other open items leaving the clicked item visible. It is possible to hide all other items and minimize your most recently item with command+option+h+m. This is a combination of command+option+h - Hide Others and command+option+m - Minimize.»\n",
      "[5] «Cmd+` of course will work but I do it in different way. I do the Cmd+tab when i do that, I dont release the Cmd so the opened apps are still visible. While it is visible, I will press ▼. This way it will show all your opened application with animated displayed so you can navigate using arrow keys.»\n",
      "\n",
      "[[ ## question ## ]]\n",
      "cmd+tab does not work on hidden or minimized windows\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## reasoning ## ]]`, then `[[ ## response ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m[[ ## reasoning ## ]]\n",
      "The Command + Tab shortcut on macOS is designed to switch between applications that are currently open and visible on the screen. However, it does not work with minimized or hidden windows because these applications are not actively running in the foreground. When an application is minimized, it is not considered \"open\" in the same way as an application that is currently displayed on the screen. Therefore, the Command + Tab function will not cycle through minimized applications. To switch to a minimized application, you would typically need to either click on its icon in the Dock or use a different keyboard shortcut that specifically targets minimized windows.\n",
      "\n",
      "[[ ## response ## ]]\n",
      "The Command + Tab shortcut on macOS is intended for switching between applications that are currently open and visible. It does not work with minimized or hidden windows because these applications are not actively running in the foreground. When an application is minimized, it is not considered \"open\" in the same sense as those displayed on the screen. To access a minimized application, you can either click its icon in the Dock or use a different method, such as the Mission Control feature, to view all open windows, including minimized ones.\n",
      "\n",
      "[[ ## completed ## ]]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dspy.inspect_history(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cde81211",
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = sum(\n",
    "    [x[\"cost\"] for x in lm.history if x[\"cost\"] is not None]\n",
    ")  # in USD, as calculated by LiteLLM for certain providers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fe79d5e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    reasoning='The Command + Tab shortcut on macOS is designed to switch between applications that are currently open and visible on the screen. However, it does not work with minimized or hidden windows because these applications are not actively running in the foreground. When an application is minimized, it is not considered \"open\" in the same way as an application that is currently displayed on the screen. Therefore, the Command + Tab function will not cycle through minimized applications. To switch to a minimized application, you would typically need to either click on its icon in the Dock or use a different keyboard shortcut that specifically targets minimized windows.',\n",
       "    response='The Command + Tab shortcut on macOS is intended for switching between applications that are currently open and visible. It does not work with minimized or hidden windows because these applications are not actively running in the foreground. When an application is minimized, it is not considered \"open\" in the same sense as those displayed on the screen. To access a minimized application, you can either click its icon in the Dock or use a different method, such as the Mission Control feature, to view all open windows, including minimized ones.'\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimized_rag.save(\"optimized_rag.json\")\n",
    "\n",
    "loaded_rag = RAG()\n",
    "loaded_rag.load(\"optimized_rag.json\")\n",
    "\n",
    "loaded_rag(question=\"cmd+tab does not work on hidden or minimized windows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01350ac4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
